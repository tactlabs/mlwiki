/ [Home](index.md)

# Long Short Term Memory

Long Short-Term Memory(LSTM) is an advanced version of recurrent neural network (RNN) architecture that was designed to model chronological sequences and their long-range dependencies more precisely than conventional RNNs. The basic difference between the architectures of RNN and LSTM is that the hidden layer of LSTM is a gated unit or gated cell. Unlike RNNs which have got the only single neural net layer of tanh, LSTMs comprises of three logistic sigmoid gates and one tanh layer. Gates have been introduced in order to limit the information that is passed through the cell.

**Created by Santhosh Kannan**

---

<br>