/ [Home](index.md)

# BERT

Bidirectional Encoder Representations from Transformers(BERT) is an open source machine learning framework for natural language processing. BERT is designed to help computers understand the meaning of ambiguous language in text by using surrounding text to establish context. The BERT framework was pre-trained using text from Wikipedia and can be fine-tuned with question and answer datasets. Generally, language models can only read text input in one direction but BERT is designed to read in both direction at once.

**Created by Santhosh Kannan**

---

<br>
