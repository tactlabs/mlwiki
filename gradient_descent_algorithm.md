/ [Home](index.md)

# Gradient Descent Algorithm 

Gradient Descent is an optimization algorithm used for minimizing the cost function in various machine learning algorithms. It is basically used for updating the parameters of the learning model.

Types of gradient Descent:
       - Batch Gradient Descent
       - Stochastic Gradient Descent
       - Mini Batch gradient descent

Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks.

Why is this needed ?
 Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter update