/ [Home](index.md)

# Convergence

Convergence refers to a state during training in which there is little to no change in the value of loss function with each iteration after a certain number of iteration. At this state, the loss function has attained a minima(or maxima) and additional training on the current data will not improve the model.

However, in deep learning, loss values may remain constant or nearly constant for several iterations before finally descending again, temporarily producing a false sense of convergence.

<br>

**Created by Santhosh Kannan**

---

<br>
