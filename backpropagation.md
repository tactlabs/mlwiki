/ [Home](index.md)

# Backpropagation

Backpropagation is a widely used method to reduce the loss function in a number of supervised algorithms for training feedforward neural networks, such as stochastic gradient descent.

When training a neural network by gradient descent, a loss function is calculated, which represents how good a model is performing. Using backpropagation, the gradient of loss function is calculated with respect to each of the weights of the network. By this process, every weight is updated individually which gradually reduces the loss function in many iterations.

<br>

**Created by Santhosh Kannan**

---

<br>
