/ [Home](index.md)

# Early Stopping

Early Stopping is a method for regularization in which the model is trained on the training dataset but is stopped at a point when performance on a validation dataset starts to degrade.

The time taken to train a model significantly affects a neural networks performance. Too little training will mean that the model will underfit the train and the test sets. Too much training will mean that the model will overfit the training dataset and have poor performance on the test set. Thus, early stopping is used as a compromise to stop the model's training before accuracy starts to decrease.

<br>

**Created by Santhosh Kannan**

---

<br>
